{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8628958,"sourceType":"datasetVersion","datasetId":5166378}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":5856.883932,"end_time":"2024-06-06T18:09:24.588697","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-06-06T16:31:47.704765","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np","metadata":{"papermill":{"duration":12.079665,"end_time":"2024-06-06T16:32:02.451659","exception":false,"start_time":"2024-06-06T16:31:50.371994","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T02:36:00.481190Z","iopub.execute_input":"2024-06-09T02:36:00.481590Z","iopub.status.idle":"2024-06-09T02:36:13.215045Z","shell.execute_reply.started":"2024-06-09T02:36:00.481561Z","shell.execute_reply":"2024-06-09T02:36:13.214225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/facecare-dataset-2-1/train'\ntest_dir = '/kaggle/input/facecare-dataset-2-1/valid'\nimg_height, img_width = 600, 600\nbatch_size = 32","metadata":{"papermill":{"duration":0.012498,"end_time":"2024-06-06T16:32:02.469130","exception":false,"start_time":"2024-06-06T16:32:02.456632","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T02:36:13.216778Z","iopub.execute_input":"2024-06-09T02:36:13.217781Z","iopub.status.idle":"2024-06-09T02:36:13.222305Z","shell.execute_reply.started":"2024-06-09T02:36:13.217745Z","shell.execute_reply":"2024-06-09T02:36:13.221292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport math\n\n# Data augmentation and normalization\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    brightness_range=(0.2, 1),\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Normalization\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Load and iterate training dataset\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n)\n\n# Load and iterate validation dataset\nvalidation_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n)\n# Calculate steps_per_epoch and validation_steps\nnum_train_samples = len(train_generator.filenames)\nnum_validation_samples = len(validation_generator.filenames)\n\nsteps_per_epoch = math.ceil(num_train_samples / batch_size)\nvalidation_steps = math.ceil(num_validation_samples / batch_size)","metadata":{"papermill":{"duration":1.129831,"end_time":"2024-06-06T16:32:03.603406","exception":false,"start_time":"2024-06-06T16:32:02.473575","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T02:36:13.223575Z","iopub.execute_input":"2024-06-09T02:36:13.223904Z","iopub.status.idle":"2024-06-09T02:36:15.311920Z","shell.execute_reply.started":"2024-06-09T02:36:13.223874Z","shell.execute_reply":"2024-06-09T02:36:15.311178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import class_weight\n\ntrain_labels = train_generator.classes\n\n# Compute class weights\nclass_weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n\n# Convert the class weights to a dictionary\nclass_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n\n# Print the class weights\nprint(\"Class weights:\", class_weights_dict)","metadata":{"papermill":{"duration":0.703951,"end_time":"2024-06-06T16:32:04.312217","exception":false,"start_time":"2024-06-06T16:32:03.608266","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T02:36:15.314426Z","iopub.execute_input":"2024-06-09T02:36:15.315073Z","iopub.status.idle":"2024-06-09T02:36:15.661879Z","shell.execute_reply.started":"2024-06-09T02:36:15.315032Z","shell.execute_reply":"2024-06-09T02:36:15.660943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import regularizers\n\nbase_model = tf.keras.applications.Xception(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n\n# Freeze the base model layers\n# for layer in base_model.layers:\n#     layer.trainable = False\nbase_model.trainable = False\n\nx = base_model.output\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Flatten()(x)\nx = tf.keras.layers.Dense(512, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(256, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.3)(x)\npredictions = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\nmodel = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)","metadata":{"papermill":{"duration":3.227152,"end_time":"2024-06-06T16:32:07.544512","exception":false,"start_time":"2024-06-06T16:32:04.317360","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T02:41:33.352989Z","iopub.execute_input":"2024-06-09T02:41:33.353446Z","iopub.status.idle":"2024-06-09T02:41:34.321634Z","shell.execute_reply.started":"2024-06-09T02:41:33.353415Z","shell.execute_reply":"2024-06-09T02:41:34.320622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import RMSprop\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.001)\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath='/kaggle/working/best_faceCare_model_Inception.keras',  # Path to save the model\n    monitor='val_accuracy',  # Monitor validation accuracy \n    save_best_only=True,  # Only save the best model\n    mode='max'  # Save when validation accuracy reaches its maximum\n)\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-5),\n              metrics=['accuracy'])\n# Model summary\nmodel.summary()","metadata":{"papermill":{"duration":0.034834,"end_time":"2024-06-06T16:32:08.103781","exception":false,"start_time":"2024-06-06T16:32:08.068947","status":"completed"},"tags":[],"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-06-09T02:41:34.323269Z","iopub.execute_input":"2024-06-09T02:41:34.323565Z","iopub.status.idle":"2024-06-09T02:41:34.517129Z","shell.execute_reply.started":"2024-06-09T02:41:34.323540Z","shell.execute_reply":"2024-06-09T02:41:34.516268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    epochs = 100,\n    validation_data= validation_generator,\n    class_weight=class_weights_dict,\n)","metadata":{"papermill":{"duration":5812.806543,"end_time":"2024-06-06T18:09:00.921345","exception":false,"start_time":"2024-06-06T16:32:08.114802","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T02:41:34.518151Z","iopub.execute_input":"2024-06-09T02:41:34.518412Z","iopub.status.idle":"2024-06-09T02:51:16.972717Z","shell.execute_reply.started":"2024-06-09T02:41:34.518381Z","shell.execute_reply":"2024-06-09T02:51:16.971933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss_acc(history):\n  '''Plots the training and validation loss and accuracy from a history object'''\n  acc = history.history['accuracy']\n  val_acc = history.history['val_accuracy']\n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  epochs = range(len(acc))\n\n  plt.plot(epochs, acc, 'bo', label='Training accuracy')\n  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n  plt.title('Training and validation accuracy')\n  plt.legend()\n\n  plt.figure()\n\n  plt.plot(epochs, loss, 'bo', label='Training Loss')\n  plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n  plt.title('Training and validation loss')\n  plt.legend()\n\n  plt.show()","metadata":{"papermill":{"duration":0.177134,"end_time":"2024-06-06T18:09:01.267037","exception":false,"start_time":"2024-06-06T18:09:01.089903","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T02:51:16.974866Z","iopub.execute_input":"2024-06-09T02:51:16.975191Z","iopub.status.idle":"2024-06-09T02:51:16.982708Z","shell.execute_reply.started":"2024-06-09T02:51:16.975164Z","shell.execute_reply":"2024-06-09T02:51:16.981791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_acc(history)","metadata":{"papermill":{"duration":0.615156,"end_time":"2024-06-06T18:09:02.049496","exception":false,"start_time":"2024-06-06T18:09:01.434340","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T02:51:16.983627Z","iopub.execute_input":"2024-06-09T02:51:16.983884Z","iopub.status.idle":"2024-06-09T02:51:17.588566Z","shell.execute_reply.started":"2024-06-09T02:51:16.983862Z","shell.execute_reply":"2024-06-09T02:51:17.587699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"/kaggle/working/FaceCare_Xception_v1.keras\")\nmodel.save(\"/kaggle/working/FaceCare_Xception_v1.h5\")","metadata":{"papermill":{"duration":1.026268,"end_time":"2024-06-06T18:09:03.245976","exception":false,"start_time":"2024-06-06T18:09:02.219708","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T02:51:17.589534Z","iopub.execute_input":"2024-06-09T02:51:17.589788Z","iopub.status.idle":"2024-06-09T02:51:18.196303Z","shell.execute_reply.started":"2024-06-09T02:51:17.589765Z","shell.execute_reply":"2024-06-09T02:51:18.195303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport os\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nimport cv2\nfrom PIL import Image\n\ndef load_and_preprocess_image(img_path, img_height, img_width):\n    img = image.load_img(img_path, target_size=(img_height, img_width))  # Adjust target size as needed\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = img_array / 255.0  # Normalize pixel values\n    return img_array\n\ndef compute_saliency(model, image):\n    image = tf.convert_to_tensor(image)\n    with tf.GradientTape() as tape:\n        tape.watch(image)\n        predictions = model(image)\n        loss = predictions[:, 0]  # For binary classification, assuming the first class is the positive class\n    gradients = tape.gradient(loss, image)\n    saliency = tf.reduce_max(tf.abs(gradients), axis=-1)\n    return saliency.numpy()\n    \ndef show_saliency(img, img_height, img_width, model):\n    \n    test_image = load_and_preprocess_image(img, img_height, img_width)\n    saliency_map = compute_saliency(model, test_image)\n    plt.figure(figsize=(10, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.title(\"Original Image\")\n    plt.imshow(test_image.squeeze(), cmap='gray')\n\n    plt.subplot(1, 2, 2)\n    plt.title(\"Saliency Map\")\n    plt.imshow(saliency_map.squeeze(), cmap='hot')\n\n    plt.show()\n    \ndef preprocess_image(img_path, target_size=(img_height, img_width)):\n    img = Image.open(img_path)\n    img = img.resize(target_size)\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n    img_array = img_array / 255.0  # Normalize the image\n    return img_array\n\ndef make_prediction(model, img_path):\n    img_array = preprocess_image(img_path)\n    prediction = model.predict(img_array)[0][0]  # Get the predicted probability for the class\n    if prediction > 0.5:\n        return \"No Acne\", prediction\n    else:\n        return \"Acne\", prediction","metadata":{"papermill":{"duration":0.374568,"end_time":"2024-06-06T18:09:03.790242","exception":false,"start_time":"2024-06-06T18:09:03.415674","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T02:51:18.197668Z","iopub.execute_input":"2024-06-09T02:51:18.197997Z","iopub.status.idle":"2024-06-09T02:51:18.409532Z","shell.execute_reply.started":"2024-06-09T02:51:18.197942Z","shell.execute_reply":"2024-06-09T02:51:18.408529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img1 = \"/kaggle/input/facecare-dataset-2-1/predAcne.jpg\"\nimg2 = \"/kaggle/input/facecare-dataset-2-1/predAcne1.jpg\"\nimg3 = \"/kaggle/input/facecare-dataset-2-1/predNoAcne.png\"\n\nprediction1, probability1 = make_prediction(model, img1)\nprediction2, probability2 = make_prediction(model, img2)\nprediction3, probability3 = make_prediction(model, img3)\n\nprint(f\"Prediction: {prediction1}\")\nprint(f\"Predicted Probability: {probability1}\")\n\nimg = Image.open(img1)\nplt.imshow(img)\nplt.title(f\"Prediction: {prediction1} ({probability1:.2f})\")\nplt.axis('off')  # Hide the axes\nplt.show()\n\nprint(f\"Prediction: {prediction2}\")\nprint(f\"Predicted Probability: {probability2}\")\n\nimg = Image.open(img2)\nplt.imshow(img)\nplt.title(f\"Prediction: {prediction2} ({probability2:.2f})\")\nplt.axis('off')  # Hide the axes\nplt.show()\n\nprint(f\"Prediction: {prediction2}\")\nprint(f\"Predicted Probability: {probability2}\")\n\nimg = Image.open(img3)\nplt.imshow(img)\nplt.title(f\"Prediction: {prediction3} ({probability3:.2f})\")\nplt.axis('off')  # Hide the axes\nplt.show()","metadata":{"papermill":{"duration":11.028635,"end_time":"2024-06-06T18:09:14.987292","exception":false,"start_time":"2024-06-06T18:09:03.958657","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T02:51:18.410757Z","iopub.execute_input":"2024-06-09T02:51:18.411082Z","iopub.status.idle":"2024-06-09T02:51:24.274906Z","shell.execute_reply.started":"2024-06-09T02:51:18.411056Z","shell.execute_reply":"2024-06-09T02:51:24.273950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_saliency(img1, img_height, img_width, model)\nshow_saliency(img2, img_height, img_width, model)\nshow_saliency(img3, img_height, img_width, model)","metadata":{"papermill":{"duration":6.489567,"end_time":"2024-06-06T18:09:21.668278","exception":false,"start_time":"2024-06-06T18:09:15.178711","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T02:51:24.276132Z","iopub.execute_input":"2024-06-09T02:51:24.276433Z","iopub.status.idle":"2024-06-09T02:51:28.387053Z","shell.execute_reply.started":"2024-06-09T02:51:24.276408Z","shell.execute_reply":"2024-06-09T02:51:28.386137Z"},"trusted":true},"execution_count":null,"outputs":[]}]}